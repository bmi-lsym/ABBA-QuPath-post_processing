{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "%run LSYM_ABBA_QuPath.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ USER INPUT REQUIRED -------\n",
    "\n",
    "# Please set the string variables below to specify the input and output data folders:\n",
    "\n",
    "# Location of the ABBA state .json file:\n",
    "ABBA_json=\"D:\\\\Alex\\\\EPFL\\\\Data\\\\Confocal\\\\May1322_posthoc_confon_VMHvl\\\\FV7689_eYFP\\\\ABBA\\\\FV7689_aligned.json\"\n",
    "#ABBA_json=\"D:\\Alex\\EPFL\\Data\\Confocal\\Nov03_Nov0521_MeA_VGATCre_synaptophysin_Aiste\\FV6570\\ABBA\\\\J30063_ABBA-new-thickness-fill-gap.json\"\n",
    "\n",
    "# Please specify the folder name for creating the output sub-folders:\n",
    "data_path=\"D:\\\\Alex\\\\EPFL\\\\Data\\\\Confocal\\\\May1322_posthoc_confon_VMHvl\\\\FV7689_eYFP\\\\Quantification\\\\\"\n",
    "#data_path=\"D:\\\\Alex\\\\EPFL\\\\Papers\\\\Paper_AStria_Michael\\\\J30063_D1R_tdT\\\\\"\n",
    "\n",
    "# Sub-folder names for the extracted original data and for the processed summary data:\n",
    "path_prefix=data_path+\"input_dataset\\\\\"\n",
    "path_prefix_results=data_path+\"results\\\\\"\n",
    "\n",
    "# Custom prefix for the summary data files:\n",
    "result_filename=\"FV7689_\"\n",
    "#result_filename=\"J30063_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parsing the ABBA project and creating the output subfolders...\n",
    "df_atlas, df_index = create_subfolders(ABBA_json, path_prefix, path_prefix_results, result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use automatically created index file as a template to modify the list of images for processing\n",
    "# AP coordinates of slices in the index file are approximate; these will be re-evaluated later on \n",
    "\n",
    "# An optional boolean column \"Swap_sides\" (possible values: True or False), together with the string column \"Swap_node\" \n",
    "# (the latter expected only if the Swap_sides flag is True), can be used to force swap left and right sides of the atlas sub-tree.\n",
    "# If both columns are present, and if \"Swap_sides\" is True for a given image, the whole sub-tree of the atlas\n",
    "# below the specified node will be swapped between the left and the right sides. \n",
    "# This could be is useful when two parts of the brain (e.g. detached posterior parts of cortex)\n",
    "# were accidentally swapped during mounting procedure.\n",
    "# The swap operation will be logged by setting a flag \"swapped_sides_flag\" to 1 in the combined output data file.\n",
    "\n",
    "# Name of the working index file, optionally edited as described above (location defined by path_prefix variable):\n",
    "#index_filename=\"J30063_autoindex_test.xlsx\"\n",
    "\n",
    "index_filename=\"FV7689_index.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the working index file\n",
    "\n",
    "df_index, swap_pos = read_index_file(index_filename, path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data from QuPath\n",
    "# Individual .csv files with annotations and detections will be created for every image\n",
    "\n",
    "# ! This step may take time and does NOT have to be repeated if it was done previously\n",
    "# That is, if corresponding .csv file already exist, it is recommended to skip to the next step \n",
    "\n",
    "idx_files_list, dets_files_list, classes_list = extract_QuPath_data(df_index, path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading the annotation and detection data files and pre-processing\n",
    "\n",
    "df, df_dets = load_csv_data(df_index, swap_pos, classes_list, path_prefix, path_prefix_results, result_filename, df_atlas)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " File(s) with the detection coordinates can be e.g. used directly to plot using Brainrender package \n",
    "  (https://github.com/brainglobe/brainrender; for details see: Claudi et al., 2020. \n",
    "  “Brainrender. A Python Based Software for Visualisation of Neuroanatomical and Morphological Data.” \n",
    "  Cold Spring Harbor Laboratory. https://doi.org/10.1101/2020.02.23.961748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into the left and the right sub-trees, collating the data and saving the intermediate results   \n",
    "# The output is a list of 6 dataframe objects that can be used later on:\n",
    "# [df_left, df_left_tree, df_left_collated, df_right, df_right_tree, df_right_collated]\n",
    "\n",
    "df_list = process_left_right_trees(df, classes_list, path_prefix_results, result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -> CHOOSE the output file format\n",
    "\n",
    "save_mode=\"csv\" \n",
    "#save_mode=\"xlsx\"\n",
    "\n",
    "\n",
    "## -> Below, please uncomment/comment the blocks of commands to CHOOSE ONE of filters for the output summary data\n",
    "## -> The filter type is set by the value of \"mode\" variable and a few associated variables\n",
    "## -> customizable for a desired content of the summary\n",
    "\n",
    "\n",
    "## summarize for all the terminal leaves of the atlas tree\n",
    "\n",
    "#mode=1  \n",
    "#super_list=[\"root\"]\n",
    "#term_flag=True\n",
    "#file_suffix=\"whole_tree\"\n",
    "\n",
    "## OR summarize for the whole atlas tree\n",
    "\n",
    "mode=2 \n",
    "super_list=[\"root\"]\n",
    "term_flag=False\n",
    "file_suffix=\"whole\"\n",
    "\n",
    "\n",
    "## OR summarize for the terminal leaves descending from selected parents listed as acronyms\n",
    "\n",
    "#mode=3 \n",
    "#term_flag=True\n",
    "#super_list=[\"HY\"]#[\"TH\",\"HY\",\"PAL\",\"STR\",\"CNU\",\"CTXsp\",\"HPF\",\"OLF\",\"Isocortex\"]\n",
    "#file_suffix = \"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df_dict, right_df_dict = summary_per_ROI(df_list, super_list, classes_list, mode, save_mode, term_flag, file_suffix, path_prefix_results, result_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " The main script is finished, all results were saved in the output files. The files can be further processed to sort/plot\n",
    " density distributions per brain area or to plot the spatial AP profiles of detectons.\n",
    "\n",
    " For these purposes, scripts for IgorPro 7 (Wavemetrics Inc) are available, \n",
    " the scripts also support averaging results across different datasets (= brains).\n",
    "\n",
    " In the following cells, some example visualizations are performed to briefly check the data.\n",
    " Horizontal bar graphs and AP-distribution graphs can be generated by the mentioned IgorPro scripts.\n",
    " Plotting works on the data from the Pandas dataframes which remain in memory after storing in the output files. \n",
    "\n",
    " The data remaining in memory after the script has finished, are described below:\n",
    " \n",
    " -> classes_list is the list of names of the detection classes. The default (unclassified) set is not included\n",
    " and is referred to as \"Detections\"\n",
    "\n",
    " -> df_list: ordered list of references to dataframes objects \n",
    " [df_left, df_left_tree, df_left_collated, df_right, df_right_tree, df_right_collated]\n",
    " These contain the global dataset, hyerarchical tree and collated data separately for the left and the right sides \n",
    "\n",
    " -> left_df_dict and right_df_dict are the dictionaries pointing to the dataframes generated in the previous cell, \n",
    " with the spatial distribution of the detection counts and detection densities vs AP coordinate,\n",
    " as well as the total numbers across the brain areas, separately for all the detection classes. \n",
    " The dictinary keys are self-explanatory strings that can be listed using the commands\n",
    " \"left_df_dict.keys()\" or \"right_df_dict.keys()\", and the dataframes can be then accessed using \n",
    " e.g. \"left_df_dict['Num Detections']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive hierarchy plot for the LEFT-side tree results\n",
    "\n",
    "# here, set the desired class name for the output \n",
    "# (can be \"Detections\" for unclassified counts or one of the entries of the classes_list[]):\n",
    "sunburst_class=\"Detections\"\n",
    "\n",
    "tree_path=[\"level_0\"]\n",
    "for i in range(np.max(df_list[1].loc[:,\"Tree_level\"])):\n",
    "    tree_path.append(\"level_\"+str(i+1))\n",
    "\n",
    "fig2 = px.sunburst(df_list[1], path=tree_path, values='Num '+sunburst_class, color='level_4', branchvalues=\"remainder\", width=1000, height=1000)\n",
    "fig2.update_layout(title_text=\"Sunburst diagram for the LEFT-side tree (total counts across all AP levels). Class name: \"+sunburst_class, font_size=9)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive hierarchy plot for the RIGHT-side tree results\n",
    "\n",
    "# here, set the desired class name for the output \n",
    "# (can be \"Detections\" for unclassified counts or one of the entries of the classes_list[]):\n",
    "sunburst_class=\"Detections\"\n",
    "\n",
    "tree_path=[\"level_0\"]\n",
    "for i in range(np.max(df_list[4].loc[:,\"Tree_level\"])):\n",
    "    tree_path.append(\"level_\"+str(i+1))\n",
    "\n",
    "fig1 = px.sunburst(df_list[4], path=tree_path, values='Num '+sunburst_class, color='level_4', branchvalues=\"remainder\", width=1000, height=1000)\n",
    "fig1.update_layout(title_text=\"Sunburst diagram for the RIGHT-side tree (total counts across all AP levels). Class name: \"+sunburst_class, font_size=9)\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df_dict['detections_total'].loc[left_df_dict['detections_total'][\"Class_name\"]==to_plot_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the total number of detections in brain regions across all the slices\n",
    "# This can be useful for one group of brain areas after running the last step of analysis using\n",
    "# a single hub structure as a list, for example:\n",
    "## mode=3 \n",
    "## term_flag=True\n",
    "## super_list=[\"Isocortex\"]\n",
    "## file_suffix = \"\"\n",
    "\n",
    "# here, set the desired class name for the output \n",
    "# (can be \"Detections\" for unclassified counts or one of the entries of the classes_list[]):\n",
    "to_plot_class=\"Detections\"\n",
    "\n",
    "# Sorting by the left side values? If False, will be sorted by Right side values\n",
    "sorting_left = True\n",
    "\n",
    "df_tmp_left=left_df_dict['detections_total'].loc[left_df_dict['detections_total'][\"Class_name\"]==to_plot_class].drop(\"Root_Atlas_AP\", axis=1).drop(\"Class_name\", axis=1)\n",
    "df_tmp_right=right_df_dict['detections_total'].loc[right_df_dict['detections_total'][\"Class_name\"]==to_plot_class].drop(\"Root_Atlas_AP\", axis=1).drop(\"Class_name\", axis=1)\n",
    "df_tmp=pd.concat([df_tmp_left, df_tmp_right], ignore_index=True, sort=False).fillna(0)\n",
    "if (sorting_left):\n",
    "    sorted_df=df_tmp.sort_values(df_tmp.first_valid_index(), axis=1, ascending=False)\n",
    "else:\n",
    "    sorted_df=df_tmp.sort_values(df_tmp.last_valid_index(), axis=1, ascending=False)\n",
    "        \n",
    "brain_areas=sorted_df.columns.str.split(\";\")\n",
    "legends=[sorted_df.columns.str.split(\";\")[i][1]+\" (\"+sorted_df.columns.str.split(\";\")[i][0]+\")\" for i in range(len(brain_areas))]\n",
    "\n",
    "dets_left=sorted_df.to_numpy()[0]*(-1)\n",
    "dets_right=sorted_df.to_numpy()[1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, len(brain_areas)/8))\n",
    "\n",
    "y_pos = np.arange(len(legends))\n",
    "\n",
    "ax.barh(y_pos, dets_left, height=0.8, align='center')\n",
    "ax.barh(y_pos, dets_right, height=0.8, align='center')\n",
    "ax.set_ylim(-0.5, len(legends)-0.5)\n",
    "ax.set_yticks(y_pos, labels=legends)\n",
    "ax.yaxis.set_tick_params(labelsize=7)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') \n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Detections (#)')\n",
    "ax.set_title('Total number of detections across analyzed slices')\n",
    "\n",
    "plt.gca().legend([\"Left side\", \"Right side\"], bbox_to_anchor=(1.1, 0, 0.4, 1), loc='upper left', ncol=1, mode=\"expand\", borderaxespad=0.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the spatial AP-distribution of detections for the N_top brain areas from the previous step \n",
    "\n",
    "# here, set the desired class name for the output \n",
    "# (can be \"Detections\" for unclassified counts or one of the entries of the classes_list[]):\n",
    "to_plot_class=\"Detections\"\n",
    "\n",
    "# Please set the number of brain areas to plot:\n",
    "N_top=10\n",
    "\n",
    "areas2plot=sorted_df.columns[0:N_top]\n",
    "acronyms2plot=areas2plot.str.split(\";\")\n",
    "# if str(left_df_list[0].loc[j,i])!='nan'\n",
    "y_dets_left = [[left_df_dict[\"Num \"+to_plot_class].loc[j,i] for i in areas2plot] for j in range(left_df_dict[\"Num \"+to_plot_class].shape[0])]\n",
    "y_dets_right = [[right_df_dict[\"Num \"+to_plot_class].loc[j,i] for i in areas2plot] for j in range(right_df_dict[\"Num \"+to_plot_class].shape[0])]\n",
    "x_dets_l = [[float(j) for j in df_list[2].where(df_list[2][\"Class\"]==i[0]).dropna().reset_index().loc[0,\"ROI_Atlas_AP\"].split(\";\")] for i in acronyms2plot]\n",
    "x_dets_r = [[float(j) for j in df_list[5].where(df_list[5][\"Class\"]==i[0]).dropna().reset_index().loc[0,\"ROI_Atlas_AP\"].split(\";\")] for i in acronyms2plot]\n",
    "\n",
    "cntr=np.zeros(N_top, dtype=int)\n",
    "x_dets_left=[x[:] for x in y_dets_left]\n",
    "\n",
    "for i in range(len(y_dets_left)):\n",
    "    for j in range(N_top):\n",
    "        if (str(y_dets_left[i][j])!='nan'):\n",
    "            x_dets_left[i][j]=x_dets_l[j][cntr[j]]\n",
    "            cntr[j]+=1\n",
    "            \n",
    "cntr=np.zeros(N_top, dtype=int)\n",
    "x_dets_right=[x[:] for x in y_dets_right]\n",
    "\n",
    "for i in range(len(y_dets_right)):\n",
    "    for j in range(N_top):\n",
    "        if (str(y_dets_right[i][j])!='nan'):\n",
    "            x_dets_right[i][j]=x_dets_r[j][cntr[j]]\n",
    "            cntr[j]+=1\n",
    "\n",
    "\n",
    "legends=[i[0] for i in acronyms2plot]\n",
    "\n",
    "fig=plt.figure()\n",
    "dets_l = fig.add_axes([0.15, 0.1, 1, 1])\n",
    "dets_l.set_xlabel(\"AP coordinate (mm)\")\n",
    "dets_l.set_ylabel(\"Detections, LEFT side\")\n",
    "dets_l.plot(x_dets_left,y_dets_left)\n",
    "\n",
    "dets_r = fig.add_axes([1.4, 0.1, 1, 1])\n",
    "dets_r.set_xlabel(\"AP coordinate (mm)\")\n",
    "dets_r.set_ylabel(\"Detections, RIGHT side\")\n",
    "dets_r.plot(x_dets_right,y_dets_right)\n",
    "\n",
    "\n",
    "plt.gca().legend(legends, bbox_to_anchor=(1.1, 0, 0.35, .45), loc='upper left', ncol=1, mode=\"expand\", borderaxespad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the average density of detections in brain regions across all the slices\n",
    "# This can be useful for one group of brain areas after running the last step of analysis using\n",
    "# a single hub structure as a list, for example:\n",
    "## mode=3 \n",
    "## term_flag=True\n",
    "## super_list=[\"Isocortex\"]\n",
    "## file_suffix = \"\"\n",
    "\n",
    "# here, set the desired class name for the output \n",
    "# (can be \"Detections\" for unclassified counts or one of the entries of the classes_list[]):\n",
    "to_plot_class=classes_list[0]#\"Detections\"\n",
    "\n",
    "# Sorting by the left side values? If False, will be sorted by Right side values\n",
    "sorting_left = True\n",
    "\n",
    "\n",
    "df_tmp_left=left_df_dict['densities_total'].loc[left_df_dict['densities_total'][\"Class_name\"]==to_plot_class].drop(\"Root_Atlas_AP\", axis=1).drop(\"Class_name\", axis=1)\n",
    "df_tmp_right=right_df_dict['densities_total'].loc[right_df_dict['densities_total'][\"Class_name\"]==to_plot_class].drop(\"Root_Atlas_AP\", axis=1).drop(\"Class_name\", axis=1)\n",
    "df_tmp=pd.concat([df_tmp_left, df_tmp_right], ignore_index=True, sort=False).fillna(0)\n",
    "if (sorting_left):\n",
    "    sorted_df=df_tmp.sort_values(df_tmp.first_valid_index(), axis=1, ascending=False)\n",
    "else:\n",
    "    sorted_df=df_tmp.sort_values(df_tmp.last_valid_index(), axis=1, ascending=False)\n",
    "        \n",
    "brain_areas=sorted_df.columns.str.split(\";\")\n",
    "legends=[sorted_df.columns.str.split(\";\")[i][1]+\" (\"+sorted_df.columns.str.split(\";\")[i][0]+\")\" for i in range(len(brain_areas))]\n",
    "\n",
    "dets_left=sorted_df.to_numpy()[0]*(-1)\n",
    "dets_right=sorted_df.to_numpy()[1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, len(brain_areas)/8))\n",
    "\n",
    "y_pos = np.arange(len(legends))\n",
    "\n",
    "ax.barh(y_pos, dets_left, height=0.8, align='center')\n",
    "ax.barh(y_pos, dets_right, height=0.8, align='center')\n",
    "ax.set_ylim(-0.5, len(legends)-0.5)\n",
    "ax.set_yticks(y_pos, labels=legends)\n",
    "ax.yaxis.set_tick_params(labelsize=7)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') \n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Density of detections (1/mm$^2$)')\n",
    "ax.set_title('Average density of detections across analyzed slices')\n",
    "\n",
    "plt.gca().legend([\"Left side\", \"Right side\"], bbox_to_anchor=(1.1, 0, 0.4, 1), loc='upper left', ncol=1, mode=\"expand\", borderaxespad=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the spatial AP-distribution of detection densities for the N_top brain areas from the previous step \n",
    "\n",
    "# here, set the desired class name for the output \n",
    "# (can be \"Detections\" for unclassified counts or one of the entries of the classes_list[]):\n",
    "to_plot_class=\"Detections\"\n",
    "\n",
    "# Please set the number of brain areas to plot:\n",
    "N_top=10\n",
    "\n",
    "areas2plot=sorted_df.columns[0:N_top]\n",
    "acronyms2plot=areas2plot.str.split(\";\")\n",
    "\n",
    "y_dens_left = [[left_df_dict[\"Density_\"+to_plot_class].loc[j,i] for i in areas2plot] for j in range(left_df_dict[\"Density_\"+to_plot_class].shape[0])]\n",
    "y_dens_right = [[right_df_dict[\"Density_\"+to_plot_class].loc[j,i] for i in areas2plot] for j in range(right_df_dict[\"Density_\"+to_plot_class].shape[0])]\n",
    "x_dens_l = [[float(j) for j in df_list[2].where(df_list[2][\"Class\"]==i[0]).dropna().reset_index().loc[0,\"ROI_Atlas_AP\"].split(\";\")] for i in acronyms2plot]\n",
    "x_dens_r = [[float(j) for j in df_list[5].where(df_list[5][\"Class\"]==i[0]).dropna().reset_index().loc[0,\"ROI_Atlas_AP\"].split(\";\")] for i in acronyms2plot]\n",
    "\n",
    "cntr=np.zeros(N_top, dtype=int)\n",
    "x_dens_left=[x[:] for x in y_dens_left]\n",
    "\n",
    "for i in range(len(y_dens_left)):\n",
    "    for j in range(N_top):\n",
    "        if (str(y_dens_left[i][j])!='nan'):\n",
    "            x_dens_left[i][j]=x_dens_l[j][cntr[j]]\n",
    "            cntr[j]+=1\n",
    "            \n",
    "cntr=np.zeros(N_top, dtype=int)\n",
    "x_dens_right=[x[:] for x in y_dens_right]\n",
    "\n",
    "for i in range(len(y_dens_right)):\n",
    "    for j in range(N_top):\n",
    "        if (str(y_dens_right[i][j])!='nan'):\n",
    "            x_dens_right[i][j]=x_dens_r[j][cntr[j]]\n",
    "            cntr[j]+=1\n",
    "\n",
    "legends=[i[0] for i in acronyms2plot]\n",
    "\n",
    "fig=plt.figure()\n",
    "dens_l = fig.add_axes([0.15, 0.1, 1, 1])\n",
    "dens_l.set_xlabel(\"AP coordinate (mm)\")\n",
    "dens_l.set_ylabel(\"Detection density, LEFT side (1/mm$^2$)\")\n",
    "dens_l.plot(x_dens_left,y_dens_left)\n",
    "\n",
    "dens_r = fig.add_axes([1.4, 0.1, 1, 1])\n",
    "dens_r.set_xlabel(\"AP coordinate (mm)\")\n",
    "dens_r.set_ylabel(\"Detection density, RIGHT side (1/mm$^2$)\")\n",
    "dens_r.plot(x_dens_right,y_dens_right)\n",
    "\n",
    "\n",
    "plt.gca().legend(legends, bbox_to_anchor=(1.1, 0, 0.35, .45), loc='upper left', ncol=1, mode=\"expand\", borderaxespad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
